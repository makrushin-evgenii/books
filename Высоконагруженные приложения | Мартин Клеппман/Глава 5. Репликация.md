# Глава 5. Репликация
*Репликация* (replication) означает хранение копий одних и тех же данных на нескольких машинах, соединенных с помощью сети: для хранения близко к пользователям; для поддержания работы при отказе некоторых частей системы; для горизонтального масштабирования на чтение. *Секционирование (шардинг)* - разделение частей набора данных по нескольким машинам, который не уместила бы одна.

## 5.1. Ведущие и ведомые узлы
Узлы, в которых хранятся копии БД, называются *репликами*. Каждая операция записи в базу должна учитываться каждой репликой. Наиболее распространенное решение - репликация с ведущим узлом (leader-based replication): все записи идут только на *ведущую* (leader) реплику, а *ведомые* (followers) подтягивают их из *журнала репликации* (replication log) или *потока изменений* (change stream). Читать можно с любой реплики.

### Синхронная и асинхронная репликация
При синхронной репликации мы ждём подтверждения записи данных на ведомую реплику. При асинхронной - не ждём.  Синхронная дольше, но обеспечивает лучшую согласованность и сохранность данных. Асинхронная - быстре. 

Обычно одну ведомую реплику делают синхронной, остальные - асинхронными. Это обеспечивает оптимальную производительность, сохраняя высокий уровень устойчивости к сбоям. Такую схему называют *полусинхронной* (semi-synchronous). Когда репликация с ведущим узлом делается полностью асинхронной, при его фатальном сбое все не реплицированные операции записи теряются.

### Создание новых ведомых узлов
Нужно сделать согласованный снимок состояния БД ведущего узла на определенный момент времени и скопировать его на новый узел. Он подключается к ведущему и запросит все изменения данных, произошедшие с момента создания снимка. 

### Перебои в обслуживании узлов
#### Отказ ведомого узла: наверстывающее восстановление
Ведомый узел способен подключиться к ведущему и запросить все изменения данных, имевшие место за то время, пока он был недоступен.
#### Отказ ведущего узла: восстановление после отказа
Необходимо один из ведомых узлов сделать ведущим, перенаправить на него операции записи и репликационное чтение других узлов. Этот процесс называется *восстановлением после отказа* (failover)

### Реализация журналов репликации
#### Операторная репликация
В простейшем случае ведущий узел записывает в журнал каждый выполняемый запрос на запись *(оператор)* и отправляет этот журнал ведомым узлам. Плохо справляется с репликацией недетерминированных операций и при использовании автоматически увеличивающегося индекса.
#### Перенос журнала упреждающей записи (WAL)
Помимо записи журнала на диск, ведущий узел также отправляет его по сети ведомым узлам. А ведомые узлы, обрабатывая этот журнал, создают точные копии тех же структур данных, что и на ведущем. Связывает репликацию с подсистемой хранения.
#### Логическая (построчная) журнальная репликация
*Логический журнал* (logical log) обычно представляет собой последовательность строк, описывающих операции записи в таблицы базы на уровне строк. Формат логического журнала удобен для разбора внешними приложениями, например для загрузки в склад данных для анализа. Такая методика называется *захватом изменений данных* (change data capture).
#### Триггерная репликация
*Триггеры* (trigger) позволяют регистрировать пользовательский код, автоматически запускаемый при возникновении в БД события изменения данных (транзакции записи). Триггер записывает данные в отдельную таблицу, откуда приложение читает их и записывает в другую систему. Гибкий, но сложный и часто неэффективный подход к репликации.

## 5.2. Проблемы задержки репликации
*Задержка репликации* (replication lag) — время между операцией записи на ведущем узле и ее воспроизведением на ведомом узле. *Конечная согласованность* (eventual consistency) допускает несогласованность данных в моменте, но обещает их согласованность в будущем.

### Читаем свои же записи
Согласованность типа *"чтение после записи"* (read-after-write consistency) или *"чтение своих записей"* (read-your-writes) гарантирует, что пользователь точно увидит внесенные им же изменения. Относительно других пользователей она ничего не обещает.

### Монотонные чтения
При выполнении пользователем нескольких операций чтения из различных реплик он может наблюдать *движение в обратном направлении времени*. *Монотонное чтение записей* гарантирует, что подобная аномалия не произойдет.

### Согласованное префиксное чтение
*Согласованное префиксное чтение* (consistent prefix reads)  гарантирует, что если операции записи выполняются в определенной последовательности, то в ней же они будут и прочитаны.

### Решения проблемы задержки репликации
Если приложение с асинхронной репликацией не способно выдержать сильное увеличение задержки репликации - необходимо спроектировать систему с более сильными гарантиями, например, чтение после записи.

## 5.3. Репликация с несколькими ведущими узлами
В схеме *репликации с несколькими ведущими узлами* (multi-leader replication), или *репликации типа "главный — главный"* (master — master), или *репликации типа "активный/активный"* (active/active replication), каждый из ведущих узлов одновременно является ведомым для других ведущих.

### Сценарии использования репликации с несколькими ведущими узлами
При обычной схеме репликации с ведущим узлом последний должен быть в **одном** из ЦОДов и всем операциям записи следует проходить через этот ЦОД. В схеме с несколькими ведущими узлами можно установить ведущий узел в **каждом** из ЦОДов. Внутри каждого из ЦОДов используется обычная репликация типа "ведущий — ведомый"; между ЦОДами ведущий узел каждого ЦОДа реплицирует свои изменения ведущим узлам в других ЦОДах.

Одни и те же данные могут одновременно модифицироваться в двух различных ЦОДах, из-за чего требуется разрешение конфликтов.

### Обработка конфликтов записи
Основная проблема репликации с несколькими ведущими узлами — возможность возникновения конфликтов записи, которые требуют разрешения.

Синхронное обнаружение конфликтов записи снизит производительность и сделает бесмысленной репликацию с несколькими ведущими узлами. Асинхронная не позволит предоставить разрешение конфликтов пользователям. Лучше избегать конфликтов на уровне приложения.

База должна разрешать конфликт конвергентным способом, то есть все реплики должны сойтись к одному значению после репликации всех изменений. Есть несколько способов: присваивать операциям метку времени и выбирать записи с максимальной; приоритезировать реплики; объединять данные с реплик; вести бэк-лог конфликтов для их разрешения позже.

### Топологии репликации с несколькими ведущими узлами
*Топология репликации* (replication topology) описывает пути, по которым операции записи распространяются с одного узла на другой. Наиболее общая - каждый с каждым, так же популярны кольцо (каждый узел получает данные от одного и передаёт одному) и звезда (все узлы передают данные на один корневой и наоборот).

В топологиях кольцо и звезда отказ одного узла может прервать поток сообщений репликации между другими узлами.

## 5.4. Репликация без ведущего узла
Реализована в Dynamo-подобных базах данных: Riak, Cassandra и Voldemort.
### Запись в базу данных при отказе одного из узлов
Rлиент параллельно отправляет информацию об операции записи всем трем репликам. При чтении клиенты отправляют запросы сразу к нескольким узлам параллельно. Реплики могут вернуть разные данные, для определения актуальных используются номера версий.
- *Разрешение конфликтов при чтении.* Клиент видит неактуальные ответы от нескольких реплик и отправляет на них актуальные - полученные при чтении с другой реплики.
- *Процесс противодействия энтропии.* Фоновый процесс поиска и исправления несоответсвий в данных на репликах.

При наличии n реплик операция записи, чтобы считаться успешной, должна быть подтверждена w узлами, причем мы должны опросить как минимум r узлов для каждой операции чтения. Если w + r > n, то можно ожидать: полученное при чтении значение будет актуальным, поскольку хотя бы один из r узлов, из которых мы читаем, должен оказаться актуальным. Операции, удовлетворяющие такому условию, называют операциями *по кворуму*. Обычно n - нечетное число (3 или 5), а r=w=(n+1)/2. 

Условие кворума придаёт системе устойчивость к недоступности узлов. Например, при n = 5, w = 3, r = 3 система может позволить себе два недоступных узла.

### Ограничения согласованности по кворуму
При w+r≤n система получит более короткую задержку и более высокую доступность, но повысится вероятность прочитать устаревшие значения. Даже при w+r>n возможны граничные случаи, при которых будут возвращены устаревшие значения. 

Параметры w и r позволяют влиять на вероятность чтения устаревших значений, но не исключают её. Гарантии чтения своих записей, монотонного чтения и согласованного префиксного чтения обычно недоступны, для их реализации требуются транзакции или консенсус. 

### Нестрогие кворумы и направленная передача
*Нестрогий кворум* (sloppy quorum): для операций записи и чтения по-прежнему необходимо w и r подтверждений успешного выполнения, но при этом учитываются узлы, не входящие в число намеченных для значения n «родных» узлов.
После исправления сбоя все операции записи, временно отправленные в какой-либо узел вместо недоступного, отправляются в соответствующие "родные" узлы. Это называется *направленной передачей* (hinted handoff). 

Нестрогие кворумы особенно полезны в деле повышения доступности для записи: база данных может принимать операции записи до тех пор, пока доступны **любые** w узлов. Не дают гарантий согласованности, только сохраняемости данных "где-нибудь".

### Обнаружение конкурентных операций записи
*Выигрывает последний* (last write wins, LWW) - в базе остаётся только последняя из конкурентных записей. Возможна потеря данных.

Говорят, что операция A *происходит до* другой операции B, если B известно про A или B зависит от A либо основана на A каким-либо образом. Две операции конкурентны, если ни одна из них не происходит до другой (то есть ни одна не знает про другую).